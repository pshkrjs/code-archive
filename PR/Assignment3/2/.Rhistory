print("Accepting H0")
same <- append(same, c(classA, classB))
} else {
print("Accepting H1")
different <- append(different, c(classA, classB))
}
return(list("same" = same, "different" = different))
}
# write sets to csv
writeSets <- function(feature, same, different){
line <- c(feature)
if(length(same)){
sameLine <- "("
for(i in seq(1, length(same), 2)){
sameLine <- paste0(sameLine, "(", same[i], ":", same[i+1], ")")
if(length(same)!=i+1){
sameLine <- paste0(sameLine, ";")
}
}
sameLine <- paste0(sameLine, ")")
line <- append(line, sameLine)
} else {
line <- append(line, "NULL")
}
if(length(different)){
differentLine <- "("
for(i in seq(1, length(different), 2)){
differentLine <- paste0(differentLine, "(", different[i], ":", different[i+1], ")")
if(length(different)!=i+1){
differentLine <- paste0(differentLine, ";")
}
}
differentLine <- paste0(differentLine, ")")
line <- append(line, differentLine)
} else {
line <- append(line, ("NULL"))
}
write.table(t(line), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE, append = TRUE)
}
write.table(t(c("Feature", "Same", "Different")), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE)
# For each feature check similarity of data for various classes
for( i in 1:length(features)){
same <- c()
different <- c()
for( j in 1:(length(classes)-1)){
for( k in (j+1):length(classes)){
cat(paste0("\nCalculations for Feature ", featurenames[i], " with classes ", classnames[j], " and ", classnames[k], ":\n"))
# data from class 1 to be compared
X <- features[(sum(classes[0:(j-1)])+1):sum(classes[0:j]), i]
# data from class 2 to be compared
Y <- features[(sum(classes[0:(k-1)])+1):sum(classes[0:k]), i]
# number of datapoints in each class
n <- c(as.numeric(classes[j]), as.numeric(classes[k]))
# sample mean for each class
xBar <- c(mean(X), mean(Y))
print(paste0("sample mean for ", featurenames[i], "=", xBar[1], " in class ", classnames[j]))
print(paste0("sample mean for ", featurenames[i], "=", xBar[2], " in class ", classnames[k]))
# standard deviation for each class
sigma <- c(sd(X)*(sqrt((length(X)-1)/length(X))), sd(Y)*(sqrt((length(Y)-1)/length(Y))))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[1], " in class ", classnames[j]))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[2], " in class ", classnames[k]))
# standard difference
sigma2 <- stdDiff(1, 2, sigma, n)
print(paste0("standard difference for ", featurenames[i], "=", sigma2))
# standard normal
z <- (xBar[1]-xBar[2])/sigma2
z <- abs(z)
zT <- z * 100
zT
zT <- ( zT %/% 10 ) / 10
zT
zR <- ( zT * 10 ) + 1
zC <- z - zT
zC <- zC*1000
zC <- ((zC %/% 10)) + 2
zC
zR
if(z>3)
z <- 0.4999
else {
z <- ztable[zR, zC]
}
print(paste0("standard normal for ", featurenames[i], "=", z))
sets <- addToSet(z, alpha, classnames[j], classnames[k], same, different)
same <- c(sets["same"][[1]])
different <- c(sets["different"][[1]])
}
}
writeSets(featurenames[i], same, different)
}
# specify working directory
setwd("~/Stuff/Dropbox/Workspace/PR/Assignment3/1")
# specify input and output files
input_file <- "data2.csv"
output_file <- paste0("output_", input_file)
# get significance value
# a <- readline(prompt = "Enter significance level: ")
# alpha <- as.integer(a)
alpha <- 5
# read input
data <- read.csv(input_file, header = TRUE, sep = ",")
# rearrange data
data <- data[order(data$Class),]
# read ztable
ztable <- read.csv("ztable.csv", header = T, sep = ",")
# get classes with frequency
classes <- table(data$Class)
# get features
features <- data[,1:(length(data)-1)]
# get featurenames
featurenames <- dimnames(features)[[2]]
# get classnames
classnames <- dimnames(classes)[[1]]
# function to calculate standard difference
stdDiff <- function(classA, classB, sigma, n){
return(sqrt((sigma[classA]^2/n[classA])+(sigma[classB]^2/n[classB])))
}
# function to add classes to same or different sets
addToSet <- function(z, alpha, classA, classB, same, different){
# if z-score <= critical value accept H0 else accept H1
if (abs(z)*200 <= 100-alpha){
print("Accepting H0")
same <- append(same, c(classA, classB))
} else {
print("Accepting H1")
different <- append(different, c(classA, classB))
}
return(list("same" = same, "different" = different))
}
# write sets to csv
writeSets <- function(feature, same, different){
line <- c(feature)
if(length(same)){
sameLine <- "("
for(i in seq(1, length(same), 2)){
sameLine <- paste0(sameLine, "(", same[i], ":", same[i+1], ")")
if(length(same)!=i+1){
sameLine <- paste0(sameLine, ";")
}
}
sameLine <- paste0(sameLine, ")")
line <- append(line, sameLine)
} else {
line <- append(line, "NULL")
}
if(length(different)){
differentLine <- "("
for(i in seq(1, length(different), 2)){
differentLine <- paste0(differentLine, "(", different[i], ":", different[i+1], ")")
if(length(different)!=i+1){
differentLine <- paste0(differentLine, ";")
}
}
differentLine <- paste0(differentLine, ")")
line <- append(line, differentLine)
} else {
line <- append(line, ("NULL"))
}
write.table(t(line), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE, append = TRUE)
}
write.table(t(c("Feature", "Same", "Different")), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE)
# For each feature check similarity of data for various classes
for( i in 1:length(features)){
same <- c()
different <- c()
for( j in 1:(length(classes)-1)){
for( k in (j+1):length(classes)){
cat(paste0("\nCalculations for Feature ", featurenames[i], " with classes ", classnames[j], " and ", classnames[k], ":\n"))
# data from class 1 to be compared
X <- features[(sum(classes[0:(j-1)])+1):sum(classes[0:j]), i]
# data from class 2 to be compared
Y <- features[(sum(classes[0:(k-1)])+1):sum(classes[0:k]), i]
# number of datapoints in each class
n <- c(as.numeric(classes[j]), as.numeric(classes[k]))
# sample mean for each class
xBar <- c(mean(X), mean(Y))
print(paste0("sample mean for ", featurenames[i], "=", xBar[1], " in class ", classnames[j]))
print(paste0("sample mean for ", featurenames[i], "=", xBar[2], " in class ", classnames[k]))
# standard deviation for each class
sigma <- c(sd(X)*(sqrt((length(X)-1)/length(X))), sd(Y)*(sqrt((length(Y)-1)/length(Y))))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[1], " in class ", classnames[j]))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[2], " in class ", classnames[k]))
# standard difference
sigma2 <- stdDiff(1, 2, sigma, n)
print(paste0("standard difference for ", featurenames[i], "=", sigma2))
# standard normal
z <- (xBar[1]-xBar[2])/sigma2
z <- abs(z)
zT <- z * 100
zT
zT <- ( zT %/% 10 ) / 10
zT
zR <- ( zT * 10 ) + 1
zC <- z - zT
zC <- zC*1000
zC <- ((zC %/% 10)) + 2
zC
zR
if(z>3)
z <- 0.4999
else {
z <- ztable[zR, zC]
}
print(paste0("standard normal for ", featurenames[i], "=", z))
sets <- addToSet(z, alpha, classnames[j], classnames[k], same, different)
same <- c(sets["same"][[1]])
different <- c(sets["different"][[1]])
}
}
writeSets(featurenames[i], same, different)
}
# specify working directory
setwd('~/Workspace/PR/Assignment3/1/')
# specify input and output files
input_file <- "data2.csv"
output_file <- paste0("output_", input_file)
# get significance value
# a <- readline(prompt = "Enter significance level: ")
# alpha <- as.integer(a)
alpha <- 5
# read input
data <- read.csv(input_file, header = TRUE, sep = ",")
# rearrange data
data <- data[order(data$Class),]
# read ztable
ztable <- read.csv("ztable.csv", header = T, sep = ",")
# get classes with frequency
classes <- table(data$Class)
# get features
features <- data[,1:(length(data)-1)]
# get featurenames
featurenames <- dimnames(features)[[2]]
# get classnames
classnames <- dimnames(classes)[[1]]
# function to calculate standard difference
stdDiff <- function(classA, classB, sigma, n){
return(sqrt((sigma[classA]^2/n[classA])+(sigma[classB]^2/n[classB])))
}
# function to add classes to same or different sets
addToSet <- function(z, alpha, classA, classB, same, different){
# if z-score <= critical value accept H0 else accept H1
if (abs(z)*200 <= 100-alpha){
print("Accepting H0")
same <- append(same, c(classA, classB))
} else {
print("Accepting H1")
different <- append(different, c(classA, classB))
}
return(list("same" = same, "different" = different))
}
# write sets to csv
writeSets <- function(feature, same, different){
line <- c(feature)
if(length(same)){
sameLine <- "("
for(i in seq(1, length(same), 2)){
sameLine <- paste0(sameLine, "(", same[i], ":", same[i+1], ")")
if(length(same)!=i+1){
sameLine <- paste0(sameLine, ";")
}
}
sameLine <- paste0(sameLine, ")")
line <- append(line, sameLine)
} else {
line <- append(line, "NULL")
}
if(length(different)){
differentLine <- "("
for(i in seq(1, length(different), 2)){
differentLine <- paste0(differentLine, "(", different[i], ":", different[i+1], ")")
if(length(different)!=i+1){
differentLine <- paste0(differentLine, ";")
}
}
differentLine <- paste0(differentLine, ")")
line <- append(line, differentLine)
} else {
line <- append(line, ("NULL"))
}
write.table(t(line), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE, append = TRUE)
}
write.table(t(c("Feature", "Same", "Different")), output_file, row.names = FALSE, col.names = FALSE, sep = ",", quote = FALSE)
# For each feature check similarity of data for various classes
for( i in 1:length(features)){
same <- c()
different <- c()
for( j in 1:(length(classes)-1)){
for( k in (j+1):length(classes)){
cat(paste0("\nCalculations for Feature ", featurenames[i], " with classes ", classnames[j], " and ", classnames[k], ":\n"))
# data from class 1 to be compared
X <- features[(sum(classes[0:(j-1)])+1):sum(classes[0:j]), i]
# data from class 2 to be compared
Y <- features[(sum(classes[0:(k-1)])+1):sum(classes[0:k]), i]
# number of datapoints in each class
n <- c(as.numeric(classes[j]), as.numeric(classes[k]))
# sample mean for each class
xBar <- c(mean(X), mean(Y))
print(paste0("sample mean for ", featurenames[i], "=", xBar[1], " in class ", classnames[j]))
print(paste0("sample mean for ", featurenames[i], "=", xBar[2], " in class ", classnames[k]))
# standard deviation for each class
sigma <- c(sd(X)*(sqrt((length(X)-1)/length(X))), sd(Y)*(sqrt((length(Y)-1)/length(Y))))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[1], " in class ", classnames[j]))
print(paste0("standard deviation for ", featurenames[i], "=", sigma[2], " in class ", classnames[k]))
# standard difference
sigma2 <- stdDiff(1, 2, sigma, n)
print(paste0("standard difference for ", featurenames[i], "=", sigma2))
# standard normal
z <- (xBar[1]-xBar[2])/sigma2
z <- abs(z)
zT <- z * 100
zT
zT <- ( zT %/% 10 ) / 10
zT
zR <- ( zT * 10 ) + 1
zC <- z - zT
zC <- zC*1000
zC <- ((zC %/% 10)) + 2
zC
zR
if(z>3)
z <- 0.4999
else {
z <- ztable[zR, zC]
}
print(paste0("standard normal for ", featurenames[i], "=", z))
sets <- addToSet(z, alpha, classnames[j], classnames[k], same, different)
same <- c(sets["same"][[1]])
different <- c(sets["different"][[1]])
}
}
writeSets(featurenames[i], same, different)
}
setwd("~/Stuff/Dropbox/Workspace/PR/Assignment3/2")
library(VGAM)
library(MASS)
data <- read.csv("data_weibull.csv", header = TRUE, sep = ",")
data <- data[order(data$A),]
N <- length(data)
n <- N
accepted <- c()
pareto.MLE <- function(X){
n <- length(X)
m <- min(X)
a <- n/sum(log(X)-log(m))
return( c(m,a) )
}
checkDistribution <- function(distribution, accepted){
data2 <- data
for(j in 1:(ceiling(0.02*N))){
cat("\r", "Iteration ", j, ":")
dataMean <- mean(data2)
critical_value <- 1.63/sqrt(n)
frequency <- table(data2)
cfrequency <- c()
fo <- c()
for(i in 1:nrow(frequency)){
cfrequency <- append(cfrequency, sum(frequency[1:i]))
fo <- append(fo, cfrequency[i]/n)
}
values <- dimnames(frequency)
values <- as.numeric(values[[1]])
if(distribution == "NORMAL"){
fe <- pnorm(values, mean = dataMean, sd = sd(data)*(sqrt((n-1)/n))) # normal distribution
} else if(distribution == "EXPONENTIAL"){
fe <- pexp(values, rate=1/dataMean) # exponential distribution
} else if(distribution == "PARETO"){
params <- pareto.MLE(data2)
fe <- ppareto(values, scale = round(params[1]), shape = round(params[2])) # pareto distribution
} else if(distribution == "GAMMA"){
params <- fitdistr(data2, "gamma")
fe <- pgamma(values, shape = round(params[[1]][1]), rate = round(params[[1]][2])) # gamma distribution
} else {
stop(simpleError(paste0(distribution, " IS AN UNKNOWN DISTRIBUTION")))
}
dn <- abs(fe-fo)
maxDn <- max(dn)
if(!is.na(maxDn)){
if(maxDn <= critical_value){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA FOLLOWS ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, maxDn)
break
}
}
if((data2[1]-dataMean) < (data2[n]-dataMean)){
data2 <- data2[1:(n-1)]
} else{
data2 <- data2[2:n]
}
n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
setwd('~/Workspace/PR/Assignment3/2/')
library(VGAM)
library(MASS)
data <- read.csv("data_weibull.csv", header = TRUE, sep = ",")
data <- data[order(data$A),]
N <- length(data)
n <- N
accepted <- c()
pareto.MLE <- function(X){
n <- length(X)
m <- min(X)
a <- n/sum(log(X)-log(m))
return( c(m,a) )
}
checkDistribution <- function(distribution, accepted){
data2 <- data
for(j in 1:(ceiling(0.02*N))){
cat("\r", "Iteration ", j, ":")
dataMean <- mean(data2)
critical_value <- 1.63/sqrt(n)
frequency <- table(data2)
cfrequency <- c()
fo <- c()
for(i in 1:nrow(frequency)){
cfrequency <- append(cfrequency, sum(frequency[1:i]))
fo <- append(fo, cfrequency[i]/n)
}
values <- dimnames(frequency)
values <- as.numeric(values[[1]])
if(distribution == "NORMAL"){
fe <- pnorm(values, mean = dataMean, sd = sd(data)*(sqrt((n-1)/n))) # normal distribution
} else if(distribution == "EXPONENTIAL"){
fe <- pexp(values, rate=1/dataMean) # exponential distribution
} else if(distribution == "PARETO"){
params <- pareto.MLE(data2)
fe <- ppareto(values, scale = round(params[1]), shape = round(params[2])) # pareto distribution
} else if(distribution == "GAMMA"){
params <- fitdistr(data2, "gamma")
fe <- pgamma(values, shape = round(params[[1]][1]), rate = round(params[[1]][2])) # gamma distribution
} else {
stop(simpleError(paste0(distribution, " IS AN UNKNOWN DISTRIBUTION")))
}
dn <- abs(fe-fo)
maxDn <- max(dn)
if(!is.na(maxDn)){
if(maxDn <= critical_value){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA FOLLOWS ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, maxDn)
break
}
}
if((data2[1]-dataMean) < (data2[n]-dataMean)){
data2 <- data2[1:(n-1)]
} else{
data2 <- data2[2:n]
}
n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
