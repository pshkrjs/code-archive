n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
setwd('~/Workspace/PR/Assignment3/2/')
library(VGAM)
library(MASS)
data <- read.csv("data_exp.csv", header = TRUE, sep = ",")
data <- data[order(data$A),]
N <- length(data)
n <- N
accepted <- c()
pareto.MLE <- function(X){
n <- length(X)
m <- min(X)
a <- n/sum(log(X)-log(m))
return( c(m,a) )
}
checkDistribution <- function(distribution, accepted){
data2 <- data
for(j in 1:(ceiling(0.02*N))){
cat("\r", "Iteration ", j, ":")
dataMean <- mean(data2)
critical_value <- 1.63/sqrt(n)
frequency <- table(data2)
cfrequency <- c()
fo <- c()
for(i in 1:nrow(frequency)){
cfrequency <- append(cfrequency, sum(frequency[1:i]))
fo <- append(fo, cfrequency[i]/n)
}
values <- dimnames(frequency)
values <- as.numeric(values[[1]])
if(distribution == "NORMAL"){
fe <- pnorm(values, mean = dataMean, sd = sd(data)*(sqrt((n-1)/n))) # normal distribution
} else if(distribution == "EXPONENTIAL"){
fe <- pexp(values, rate=1/dataMean) # exponential distribution
} else if(distribution == "PARETO"){
params <- pareto.MLE(data2)
fe <- ppareto(values, scale = round(params[1]), shape = round(params[2])) # pareto distribution
} else if(distribution == "GAMMA"){
params <- fitdistr(data2, "gamma")
fe <- pgamma(values, shape = round(params[[1]][1]), rate = round(params[[1]][2])) # gamma distribution
} else {
stop(simpleError(paste0(distribution, " IS AN UNKNOWN DISTRIBUTION")))
}
dn <- abs(fe-fo)
maxDn <- max(dn)
if(!is.na(maxDn)){
if(maxDn <= critical_value){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA FOLLOWS ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, maxDn)
break
}
}
if((data2[1]-dataMean) < (data2[n]-dataMean)){
data2 <- data2[1:(n-1)]
} else{
data2 <- data2[2:n]
}
n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
setwd('~/Workspace/PR/Assignment3/2/')
library(VGAM)
library(MASS)
data <- read.csv("data_gamma.csv", header = TRUE, sep = ",")
data <- data[order(data$A),]
N <- length(data)
n <- N
accepted <- c()
pareto.MLE <- function(X){
n <- length(X)
m <- min(X)
a <- n/sum(log(X)-log(m))
return( c(m,a) )
}
checkDistribution <- function(distribution, accepted){
data2 <- data
for(j in 1:(ceiling(0.02*N))){
cat("\r", "Iteration ", j, ":")
dataMean <- mean(data2)
critical_value <- 1.63/sqrt(n)
frequency <- table(data2)
cfrequency <- c()
fo <- c()
for(i in 1:nrow(frequency)){
cfrequency <- append(cfrequency, sum(frequency[1:i]))
fo <- append(fo, cfrequency[i]/n)
}
values <- dimnames(frequency)
values <- as.numeric(values[[1]])
if(distribution == "NORMAL"){
fe <- pnorm(values, mean = dataMean, sd = sd(data)*(sqrt((n-1)/n))) # normal distribution
} else if(distribution == "EXPONENTIAL"){
fe <- pexp(values, rate=1/dataMean) # exponential distribution
} else if(distribution == "PARETO"){
params <- pareto.MLE(data2)
fe <- ppareto(values, scale = round(params[1]), shape = round(params[2])) # pareto distribution
} else if(distribution == "GAMMA"){
params <- fitdistr(data2, "gamma")
fe <- pgamma(values, shape = round(params[[1]][1]), rate = round(params[[1]][2])) # gamma distribution
} else {
stop(simpleError(paste0(distribution, " IS AN UNKNOWN DISTRIBUTION")))
}
dn <- abs(fe-fo)
maxDn <- max(dn)
if(!is.na(maxDn)){
if(maxDn <= critical_value){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA FOLLOWS ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, maxDn)
break
}
}
if((data2[1]-dataMean) < (data2[n]-dataMean)){
data2 <- data2[1:(n-1)]
} else{
data2 <- data2[2:n]
}
n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
setwd('~/Workspace/PR/Assignment3/2/')
library(VGAM)
library(MASS)
data <- read.csv("data_pareto.csv", header = TRUE, sep = ",")
data <- data[order(data$A),]
N <- length(data)
n <- N
accepted <- c()
pareto.MLE <- function(X){
n <- length(X)
m <- min(X)
a <- n/sum(log(X)-log(m))
return( c(m,a) )
}
checkDistribution <- function(distribution, accepted){
data2 <- data
for(j in 1:(ceiling(0.02*N))){
cat("\r", "Iteration ", j, ":")
dataMean <- mean(data2)
critical_value <- 1.63/sqrt(n)
frequency <- table(data2)
cfrequency <- c()
fo <- c()
for(i in 1:nrow(frequency)){
cfrequency <- append(cfrequency, sum(frequency[1:i]))
fo <- append(fo, cfrequency[i]/n)
}
values <- dimnames(frequency)
values <- as.numeric(values[[1]])
if(distribution == "NORMAL"){
fe <- pnorm(values, mean = dataMean, sd = sd(data)*(sqrt((n-1)/n))) # normal distribution
} else if(distribution == "EXPONENTIAL"){
fe <- pexp(values, rate=1/dataMean) # exponential distribution
} else if(distribution == "PARETO"){
params <- pareto.MLE(data2)
fe <- ppareto(values, scale = round(params[1]), shape = round(params[2])) # pareto distribution
} else if(distribution == "GAMMA"){
params <- fitdistr(data2, "gamma")
fe <- pgamma(values, shape = round(params[[1]][1]), rate = round(params[[1]][2])) # gamma distribution
} else {
stop(simpleError(paste0(distribution, " IS AN UNKNOWN DISTRIBUTION")))
}
dn <- abs(fe-fo)
maxDn <- max(dn)
if(!is.na(maxDn)){
if(maxDn <= critical_value){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA FOLLOWS ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, maxDn)
break
}
}
if((data2[1]-dataMean) < (data2[n]-dataMean)){
data2 <- data2[1:(n-1)]
} else{
data2 <- data2[2:n]
}
n <- n-1
if(j==floor(0.02*N)){
cat("\n")
print(paste0("CALCULATIONS FOR ", distribution, " DISTRIBUTION:"))
print("SUMMARY OF Fo")
print(rbind(head(fo),tail(fo)))
print("SUMMARY OF Fe")
print(rbind(head(fe),tail(fe)))
print(paste0("MAX Dn = ", maxDn))
print(paste0("CRITICAL VALUE = ", critical_value))
print(paste0("GIVEN DATA DOES NOT FOLLOW ", distribution, " DISTRIBUTION AFTER REMOVING ", j-1, " OUTLIERS"))
accepted <- append(accepted, 5)
}
}
return(accepted)
}
accepted <- checkDistribution("NORMAL", accepted)
accepted <- checkDistribution("EXPONENTIAL", accepted)
accepted <- checkDistribution("PARETO", accepted)
accepted <- checkDistribution("GAMMA", accepted)
distribution <- switch(which.min(accepted), "NORMAL", "EXPONENTIAL", "PARETO", "GAMMA")
if(min(accepted) != 5){
print(paste0("BEST FIT FOR GIVEN DATA IS ", distribution, " DISTRIBUTION"))
}else{
print("GIVEN DATA DOES NOT FOLLOW ANY OF THE KNOWN DISTRIBUTIONS")
}
setwd('~/Workspace/PR/Assignment3/3/')
library('DiscriMiner')
library('psych')
# read input
data <- read.csv("data1.csv", header = TRUE, sep = ",")
# rearrange data
data <- data[order(data$Class),]
data <- data.matrix(data)
no_of_cols <- ncol(data)
betweenCov1 <- function (variables, group, div_by_n = FALSE) {
verify_Xy = my_verify1(variables, group, na.rm = FALSE)
X = verify_Xy$X
y = verify_Xy$y
n = nrow(X)
p = ncol(X)
glevs = levels(y)
ng = nlevels(y)
mean_global = mean(X)
Between = matrix(0, p, p)
for (k in 1:ng) {
tmp <- y == glevs[k]
nk = sum(tmp)
mean_k = mean(X[tmp, ])
dif_k = mean_k - mean_global
if (div_by_n) {
between_k = (nk/n) * tcrossprod(dif_k)
}
else {
between_k = (nk/(n - 1)) * tcrossprod(dif_k)
}
Between = Between + between_k
}
if (is.null(colnames(variables))) {
var_names = paste("X", 1:ncol(X), sep = "")
dimnames(Between) = list(var_names, var_names)
}
else {
dimnames(Between) = list(colnames(variables), colnames(variables))
}
Between
}
my_verify1 <- function (x, y, qualitative = FALSE, na.rm = na.rm) {
if (is.null(dim(x)))
stop("\n'variables' is not a matrix or data.frame")
if (!na.rm) {
if (length(complete.cases(x)) != nrow(x))
stop("\nSorry, no missing values allowed in 'variables'")
}
if (nrow(x) != length(y))
stop("\n'variables' and 'group' have different lengths")
if (!is.vector(y) && !is.factor(y))
stop("\n'group' must be a factor")
if (!is.factor(y))
y = as.factor(y)
if (any(!is.finite(y)))
stop("\nNo missing values allowed in 'group'")
if (!qualitative) {
if (!is.matrix(x))
x <- as.matrix(x)
if (!is.numeric(x))
stop("\n'variables' must contain only numeric values")
}
else {
fac_check = sapply(x, class)
if (!is.data.frame(x) && any(fac_check != "factor"))
stop("\nA data frame with factors was expected")
}
if (is.null(colnames(x)))
colnames(x) = paste(rep("X", ncol(x)), seq_len(ncol(x)),
sep = "")
if (is.null(rownames(x)))
rownames(x) = 1L:nrow(x)
list(X = x, y = y)
}
J1 <- c()
for(x in 1:(no_of_cols-1)){
Sw <- withinCov(matrix(c(data[,x]), byrow = T, ncol = 1),data[,no_of_cols],div_by_n = T)
Sb <- betweenCov1(matrix(c(data[,x]), byrow = T, ncol = 1),data[,no_of_cols],div_by_n = T)
Sm <- Sw + Sb
J1 <- append(J1,(tr(Sm)/tr(Sw)))
}
selectedClasses <- c(which.max(J1))
corr_coeffs <- c()
classes <- data.matrix(data[,selectedClasses])
colnames(classes)<-colnames(data)[selectedClasses]
classes1 <- data.matrix(data[,-c(selectedClasses,ncol(data))])
colnames(classes1)<-colnames(data)[-c(selectedClasses,ncol(data))]
while(ncol(classes)<2){
corr_coeffs <- cor(classes, classes1[,1:(ncol(classes1))])
selectedClasses1 <- which(corr_coeffs<0.8)
if(length(selectedClasses1)>1){
classes1 <- classes1[,selectedClasses1]
} else {
classes1names<-colnames(classes1)[selectedClasses1]
classes1 <- data.matrix(classes1[,selectedClasses1])
colnames(classes1)<-classes1names
}
if(ncol(classes1)>0){
J1<-c()
for(x in 1:(ncol(classes1))){
Sw <- withinCov(cbind(classes,classes1[,x]),data[,ncol(data)],div_by_n = T)
Sb <- betweenCov(cbind(classes,classes1[,x]),data[,ncol(data)],div_by_n = T)
Sm <- Sw + Sb
J1 <- append(J1,(tr(Sm)/tr(Sw)))
}
selectedClasses <- c(which.max(J1))
classes<-cbind(classes,classes1[,selectedClasses])
colnames(classes)<-append(colnames(classes)[-ncol(classes)],colnames(classes1)[selectedClasses])
classes1names<-colnames(classes1)[-selectedClasses]
classes1 <- data.matrix(classes1[,-selectedClasses])
colnames(classes1)<-classes1names
if(ncol(classes1)==0){
break
}
}else{
break
}
}
finalSelected<-colnames(classes)
print("Features selected using forward selection:")
print(finalSelected)
setwd('~/Workspace/PR/Assignment4/')
library(dplyr)
library(radiomics)
library(mixAK)
library(EBImage)
paths<-list.files(path="~/Workspace/PR/Assignment4/Training",
pattern=".png|.jpg|.JPG",all.files=T, full.names=T, no.. = T,recursive = T)
write.table(t(c("Class","Path")), "training1.csv",row.names = F,
col.names = F,sep = ",", quote = FALSE)
write.table(t(c(1:83)),"training2.csv",row.names = F, col.names = F, sep = ",", quote = FALSE)
calcFeatures<-function(image)
{
print(image)
image_grey<-readImage(image)
dft_feature<-fft(image_grey)/sqrt(nrow(image_grey)*ncol(image_grey))
magnitude<-Mod(dft_feature)
magnitude<-magnitude[c(1:3,(nrow(magnitude)-2):nrow(magnitude)),c(1:3,(ncol(magnitude)-2):ncol(magnitude)),1]
#print(length(magnitude))
phase<-Arg(dft_feature)
phase<-phase[c(1:3,(nrow(phase)-2):nrow(phase)),c(1:3,(ncol(phase)-2):ncol(phase)),1]
#print(length(phase))
image_grey<-channel(image_grey,"gray")
image_grey<-image_grey@.Data
co_mat<-glcm(data = image_grey, angle = 0,d = 1)
feature<-calc_features(co_mat,features = c("glcm_energy","glcm_entropy","glcm_contrast","glcm_homogeneity2"))
M00<-M10<-M01<-c(0)
U00<-U11<-U02<-U20<-U12<-U21<-U03<-U30<-c(0)
#cm<-calcCentroid(image_grey)
#xbar=cm[1]
#ybar=cm[2]
for(i in 1:nrow(image_grey))
{
for(j in 1:ncol(image_grey))
{
M00<-M00+image_grey[i,j]
M10<-M10+(image_grey[i,j]*i)
M01<-M01+(image_grey[i,j]*j)
}
}
xbar=M10/M00
ybar=M01/M00
#print(xbar)
#print(ybar)
for(x in 1:nrow(image_grey))
{
for(y in 1:ncol(image_grey))
{
U00<-U00+image_grey[x,y]
U11<-U11+(image_grey[x,y]*(x-xbar)*(y-ybar))
U02<-U02+(image_grey[x,y]*((y-ybar)^2))
U20<-U20+(image_grey[x,y]*((x-xbar)^2))
U12<-U12+(image_grey[x,y]*(x-xbar)*((y-ybar)^2))
U21<-U21+(image_grey[x,y]*((x-xbar)^2)*(y-ybar))
U03<-U03+(image_grey[x,y]*((y-ybar)^3))
U30<-U30+(image_grey[x,y]*((x-xbar)^3))
}
}
n11<-U11/(U00^2)
n02<-U02/(U00^2)
n20<-U20/(U00^2)
n12<-U12/(U00^2.5)
n21<-U21/(U00^2.5)
n03<-U03/(U00^2.5)
n30<-U30/(U00^2.5)
phi <- c(
(n20+n02),
((n20-n02)^2)+(4*(n11^2)),
((n30-(3*n12))^2)+((n03-(3*n21))^2),
((n30+n12)^2)+((n03+n21)^2),
((n30-(3*n12))*(n30+n12)*((n30+n12)^2-(3*(n21+n03)^2)))+((n03-(3*n21))*(n03+n21)*((n03+n21)^2-(3*(n12+n30)^2))),
(n20-n02)*((n30+n12)^2-(n21+n03)^2)+(4*n11*(n30+n12)*(n03+n21)),
(((3*n21)-n03)*(n30+n12)*((n30+n12)^2-(3*(n21+n03)^2)))+((n30-(3*n12))*(n21+n03)*((n03+n21)^2-(3*(n30+n12)^2)))
)
feature<-append(feature,phi)
feature1<-c()
for(i in 1:length(feature))
{
feature1<-append(feature1,feature[[i]])
}
feature1<-append(feature1,c(magnitude,phase))
print(head(feature1))
return(feature1)
}
for(img in paths)
{
write.table(t(c(basename(dirname(img)),img)),"training1.csv",
row.names = F, col.names = F,sep=',',append = T)
features<-calcFeatures(img)
write.table(t(features), "training2.csv", row.names = FALSE, col.names = F,
sep = ",", quote = FALSE,append = T)
}
training1<-read.csv("training1.csv")
training2<-read.csv("training2.csv")
training<-cbind(training1,training2)
write.csv(training,file = "training.csv")
